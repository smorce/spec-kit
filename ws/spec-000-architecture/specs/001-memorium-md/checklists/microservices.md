# マイクロサービス実装チェックリスト

本ドキュメントは、仕様駆動TDDとTidy Firstの原則に基づき、分散システム品質を維持するための共通チェックリストである。開発者は各チェック項目について Red→Green→Refactor の進行に合わせて確認し、受け入れ条件と観測可能な証拠を明示的に残すこと。

## 前提
- ローカル開発環境（個人プロジェクト）での運用を想定する。
- データ暗号化は非対応（対象外としてドキュメント化する）。
- データの投入・検索は `documents/MiniRAG` 配下の MiniRAG フレームワーク（Python）経由で行う。

---

## サービス設計と境界

- [ ] **疎結合と高凝集**
  - **Red**: サービス境界外の振る舞いを誤って利用した場合に失敗するテスト（ドメイン外API呼び出し禁止など）を記述する。
  - **Green**: MiniRAGアダプタや外部ポートを介した最小実装でテストを合格させ、内部凝集を保つ。
  - **Refactor**: 公開インターフェースの命名整理やドメインサービスの分割を行い、境界定義ドキュメントを更新する。
  - **Accept基準**: コンポーネント図と依存関係リストで、外部依存がMiniRAGアダプタと契約APIに限定されている。
  - **Fail例**: 他サービスのリポジトリやDBクライアントを直接インポート／内部DTOを再利用している。
  - **観測証拠**: 依存グラフ生成ツールの出力、境界テスト結果、設計図の更新履歴。

- [ ] **独立したデプロイ**
  - **Red**: サービス単体デプロイ時に必要な設定値・シークレットが不足した場合の失敗テスト（例：環境変数モック）を追加する。
  - **Green**: 単一サービス起動スクリプトまたはCompose内で独立して動作する最小構成を実装しテストを通す。
  - **Refactor**: 起動手順書・自動化スクリプトを整理し、依存サービスをスタブ化する。
  - **Accept基準**: サービス単体で `uv run --link-mode=copy` を用いたテスト・起動が成功し、依存はモックまたは公開API経由で差し替え可能。
  - **Fail例**: 他サービスのビルドやDB初期化が必須で単体起動できない、循環依存が存在する。
  - **観測証拠**: 単体デプロイ実行ログ、テストCIジョブログ、スタブ設定資料。

## データ管理

- [ ] **Database per Service（最重要）**
  - **Red**: 他サービスのデータストアを直接参照した際に失敗するテスト（リード／ライト双方）を作成する。
  - **Green**: サービス専用のMiniRAGデータアクセス層を実装し、APIまたはイベント経由でのみ外部データと連携する。
  - **Refactor**: MiniRAGアダプタの責務分離と永続化インターフェースの整理を行う。
  - **Accept基準**: MiniRAGコレクション定義とデータアクセスコードがサービス専有で、境界越えアクセスが存在しない。
  - **Fail例**: 他サービスのMiniRAGコレクション／DBテーブルを直接操作するコードがある。
  - **観測証拠**: MiniRAG設定ファイル、依存スキャンレポート、Redテストスクリーンショット。

- [ ] **トランザクション管理**
  - **Red**: 失敗時ロールバックを検証するテスト（例：MiniRAGへの部分書き込みが停止しデータ不整合が起こらないこと）を追加する。
  - **Green**: トランザクション境界を明示した実装（Unit of Workやコンテキストマネージャ）でテストを合格させる。
  - **Refactor**: エラーハンドリングとロギングの整理を行い、トランザクションポリシーを文書化する。
  - **Accept基準**: 失敗シナリオでMiniRAGデータが期待通りにロールバックされることをテストで証明済み。
  - **Fail例**: 例外発生後に部分書き込みが残存、明示的な境界がなく副作用が拡散。
  - **観測証拠**: テスト結果、トランザクション設計メモ、ログ出力例。

- [ ] **結果整合性**
  - **Red**: 複数サービス協調の失敗パターン（イベント未到達・再試行）を再現するテストを追加し、補償動作の不足を可視化する。
  - **Green**: Sagaパターンまたは同等機構の最小実装でテストを通過させる。
  - **Refactor**: 補償アクションの共通化や状態遷移ログの整備を行う。
  - **Accept基準**: 結果整合性が必要なフローについて、補償手順とタイムアウトシナリオをドキュメント化しテストで担保。
  - **Fail例**: イベント喪失時に不整合が残存、補償処理が未実装／未文書化。
  - **観測証拠**: Saga状態図、イベントログ、失敗テストの修正コミット。

- [ ] **CQRS（検討）**
  - **Red**: 読み取り性能要件を満たさないケースを再現するベンチマーク／負荷テストを作成する。
  - **Green**: MiniRAGの読み取りと書き込みモデルを分離する実装または不要判断のテスト検証を実施する。
  - **Refactor**: クエリ用アダプタの最適化やキャッシュ戦略の整理を行い、不要判断であれば理由と計測結果を残す。
  - **Accept基準**: 採用時は読み取り系が性能要件を満たす。非採用の場合は計測根拠と意思決定をADRで記録。
  - **Fail例**: 判断根拠なしにCQRSを導入／拒否している、性能指標が未定義。
  - **観測証拠**: ベンチマーク結果、ADRリンク、MiniRAGクエリ実装差分。

## 通信とAPI契約

- [ ] **API契約の遵守**
  - **Red**: OpenAPIとの差異（フィールド欠落・型不一致）を検出する契約テストをまず追加する。
  - **Green**: スキーマバリデータ／スタブを用いて契約通りに実装しテストをパスさせる。
  - **Refactor**: ハンドラー整理・共通レスポンス生成の抽出を行い、OpenAPIを最新化する。
  - **Accept基準**: 契約テストが全て成功し、OpenAPIと実装の差分がゼロである。
  - **Fail例**: 契約外フィールドを返却、必須項目不足、OpenAPI未更新。
  - **観測証拠**: 契約テスト結果、OpenAPI差分、CIレポート。

- [ ] **通信プロトコル**
  - **Red**: 想定外の同期／非同期呼び出し選択で失敗するテスト（タイムアウト・順序保証など）を追加する。
  - **Green**: ケースに応じたREST/gRPCあるいはメッセージング実装を整備しテストを成功させる。
  - **Refactor**: 通信ポリシーの共通化やリトライ設定の抽象化を行い、ドキュメント更新。
  - **Accept基準**: 詳細設計の通信方針と実装が一致し、選定理由がADRに記録されている。
  - **Fail例**: 高遅延処理を同期呼び出ししてタイムアウト、ドキュメントと実装が乖離。
  - **観測証拠**: 通信選定ADR、テストログ、サービスメッシュ設定。

- [ ] **入力検証**
  - **Red**: 必須項目欠落／フォーマット不正などのバリデーションテストを先に追加する。
  - **Green**: バリデーションロジックを最小実装しテストを合格させる。
  - **Refactor**: バリデーションルールを共通化し、エラーメッセージを整備する。
  - **Accept基準**: 全入力に対するスキーマ検証が自動テストで網羅され、MiniRAG挿入前にすべてフィルタされる。
  - **Fail例**: テストが不正値を許容、手動チェックのみ。
  - **観測証拠**: バリデーションテスト結果、ルール定義ファイル、APIドキュメント更新。

- [ ] **エラーレスポンス**
  - **Red**: 想定エラーコード／フォーマットを検証する契約テストを追加する。
  - **Green**: 共通エラーラッパやハンドラーで定義フォーマットを実装しテストを通す。
  - **Refactor**: エラーマップを整理し、ログ出力と関連付ける。
  - **Accept基準**: 4xx/5xxの全ケースで共通JSONレスポンスが返り、OpenAPIの例示と一致する。
  - **Fail例**: フォーマットが環境ごとに揺れる、スタックトレースを直接返す。
  - **観測証拠**: 契約テスト結果、ログサンプル、OpenAPI例示差分。

## 耐障害性（レジリエンス）

- [ ] **サーキットブレーカー**
  - **Red**: 依存サービスの応答遅延／失敗をシミュレートするテストを追加する。
  - **Green**: サーキットブレーカ設定（しきい値・リセット時間）を実装し、テストを合格させる。
  - **Refactor**: 設定値を構成ファイル化し、サービスメッシュまたはライブラリ設定を共通化する。
  - **Accept基準**: 連続失敗で呼び出しが遮断され、フォールバックが発動することがテストで証明済み。
  - **Fail例**: 無限リトライで依存サービスを枯渇させる、サーキットが開かない。
  - **観測証拠**: テストログ、メトリクス（開閉状態）、設定ファイル。

- [ ] **タイムアウト**
  - **Red**: 過大な応答時間が発生した際にテストが失敗するケースを追加する。
  - **Green**: すべての外部呼び出しにタイムアウト値を設定し、テストを通す。
  - **Refactor**: 設定値の集中管理と計測ログの整備を行う。
  - **Accept基準**: タイムアウト値が設計通りに適用され、メトリクスで監視できる。
  - **Fail例**: デフォルト値任せでハング、タイムアウト発生時に未処理例外。
  - **観測証拠**: テスト結果、サービスメッシュ設定、メトリクスダッシュボード。

- [ ] **リトライ戦略**
  - **Red**: 一時障害（例：HTTP 503）が発生するテストを追加し、リトライ不足を可視化する。
  - **Green**: 指数バックオフやジッターを備えたリトライ実装でテストを合格させる。
  - **Refactor**: リトライポリシーを共通ユーティリティ化し、冪等性ドキュメントを整備する。
  - **Accept基準**: 冪等な操作のみリトライし、成功率向上と過剰呼び出し回避がテストと計測で確認できる。
  - **Fail例**: 副作用のある操作を再実行、無制限リトライ。
  - **観測証拠**: テストログ、ポリシー定義、メトリクス（成功率）。

- [ ] **フォールバック**
  - **Red**: 依存停止時のテストを追加し、フォールバック未実装を検出する。
  - **Green**: キャッシュレスポンスや機能制限などのフォールバックを実装しテストを通す。
  - **Refactor**: フォールバック選択基準と通知手順を整理する。
  - **Accept基準**: 依存不可時も定義済みフォールバックが起動し、ユーザ影響が許容範囲に収まる。
  - **Fail例**: 例外をそのまま返却、フォールバックが手動対応のみ。
  - **観測証拠**: テスト結果、運用Runbook、ログ出力。

## オブザーバビリティ（可観測性）

- [ ] **分散トレーシング（最重要）**
  - **Red**: トレースID欠落時に失敗するテスト／メトリクスを追加する。
  - **Green**: W3C Trace Contextの `traceparent` を抽出・伝播する実装を追加しテストを合格させる。
  - **Refactor**: トレーシングユーティリティを共通化し、MiniRAG連携時のトレースタグ付けを整理する。
  - **Accept基準**: すべての外部呼び出しでトレースIDが伝播し、可視化ツール上で一貫したスパンが確認できる。
  - **Fail例**: 新規リクエストでトレースIDがリセット、外部呼び出しでヘッダー未送信。
  - **観測証拠**: 分散トレーシングツールのスパンキャプチャ、テストスクリーンショット、ユーティリティコード差分。

- [ ] **構造化ロギング**
  - **Red**: 非構造化ログや機密情報漏洩を検知するテスト／リンタを追加する。
  - **Green**: JSONなど機械可読な形式でログ出力し、必要項目（タイムスタンプ、レベル、トレースID）を含める実装を行う。
  - **Refactor**: ログフィールドの標準化と不要情報の削減を行い、MiniRAG操作ログとの整合性をとる。
  - **Accept基準**: ログが統一フォーマットで出力され、監視基盤で検索可能。機密情報が含まれない。
  - **Fail例**: プレーンテキスト、個人情報をログ。
  - **観測証拠**: ログ出力例、ログスキーマ定義、監視設定。

- [ ] **メトリクス監視**
  - **Red**: 非機能要件（レスポンスタイム、エラーレート等）を満たさないケースを検出するメトリクステスト／アラートテストを追加する。
  - **Green**: 詳細設計で定義した主要メトリクスを計測し、テストでしきい値を確認する実装を行う。
  - **Refactor**: メトリクス名やラベルの整理、MiniRAGクエリのラベル付与を行う。
  - **Accept基準**: 定義済みメトリクスがすべて収集され、しきい値がドキュメントとアラートに反映されている。
  - **Fail例**: メトリクス未計測、ラベル不整合で可視化不可。
  - **観測証拠**: メトリクスダッシュボード、計測コード差分、テスト結果。

---

各チェック項目は TDD サイクルごとに証跡を残すこと。Accept基準に到達しない場合は Fail例・観測証拠を根拠に仕様・設計を再検討し、必要に応じてユーザーへ確認を取る。
